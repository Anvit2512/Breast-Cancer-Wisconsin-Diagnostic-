{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da65d44-cabb-4f02-b63e-29328c79f25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ First few rows:\n",
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0  ...          17.33           184.60      2019.0            0.1622   \n",
      "1  ...          23.41           158.80      1956.0            0.1238   \n",
      "2  ...          25.53           152.50      1709.0            0.1444   \n",
      "3  ...          26.50            98.87       567.7            0.2098   \n",
      "4  ...          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.6656           0.7119                0.2654          0.4601   \n",
      "1             0.1866           0.2416                0.1860          0.2750   \n",
      "2             0.4245           0.4504                0.2430          0.3613   \n",
      "3             0.8663           0.6869                0.2575          0.6638   \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "   fractal_dimension_worst  Unnamed: 32  \n",
      "0                  0.11890          NaN  \n",
      "1                  0.08902          NaN  \n",
      "2                  0.08758          NaN  \n",
      "3                  0.17300          NaN  \n",
      "4                  0.07678          NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "\n",
      "ðŸ”¹ Columns:\n",
      "['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32']\n",
      "\n",
      "ðŸ”¹ Data types:\n",
      "id                           int64\n",
      "diagnosis                   object\n",
      "radius_mean                float64\n",
      "texture_mean               float64\n",
      "perimeter_mean             float64\n",
      "area_mean                  float64\n",
      "smoothness_mean            float64\n",
      "compactness_mean           float64\n",
      "concavity_mean             float64\n",
      "concave points_mean        float64\n",
      "symmetry_mean              float64\n",
      "fractal_dimension_mean     float64\n",
      "radius_se                  float64\n",
      "texture_se                 float64\n",
      "perimeter_se               float64\n",
      "area_se                    float64\n",
      "smoothness_se              float64\n",
      "compactness_se             float64\n",
      "concavity_se               float64\n",
      "concave points_se          float64\n",
      "symmetry_se                float64\n",
      "fractal_dimension_se       float64\n",
      "radius_worst               float64\n",
      "texture_worst              float64\n",
      "perimeter_worst            float64\n",
      "area_worst                 float64\n",
      "smoothness_worst           float64\n",
      "compactness_worst          float64\n",
      "concavity_worst            float64\n",
      "concave points_worst       float64\n",
      "symmetry_worst             float64\n",
      "fractal_dimension_worst    float64\n",
      "Unnamed: 32                float64\n",
      "dtype: object\n",
      "\n",
      "ðŸ”¹ Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Display first few rows\n",
    "print(\"ðŸ”¹ First few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display column names\n",
    "print(\"\\nðŸ”¹ Columns:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Display data types of each column\n",
    "print(\"\\nðŸ”¹ Data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Display summary info\n",
    "print(\"\\nðŸ”¹ Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Display summary statistics (for num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be179bc-2cb2-4caf-8dfe-faed6b18e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading and Preparing Data ---\n",
      "Data prepared: 398 training samples, 171 testing samples.\n",
      "\n",
      "--- 2. Training and Evaluating Baseline Models ---\n",
      "Baseline Model Performance:\n",
      "                        Accuracy  Precision    Recall  F1-Score\n",
      "Logistic Regression     0.988304   0.990654  0.990654  0.990654\n",
      "K-Nearest Neighbors     0.959064   0.938596  1.000000  0.968326\n",
      "Support Vector Machine  0.976608   0.981308  0.981308  0.981308\n",
      "Random Forest           0.935673   0.944444  0.953271  0.948837\n",
      "\n",
      "\n",
      "--- 3. Hyperparameter Tuning with GridSearchCV (for SVM) ---\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "\n",
      "Best Parameters for SVM: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "--- 4. Hyperparameter Tuning with RandomizedSearchCV (for Random Forest) ---\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "Best Parameters for Random Forest: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 363}\n",
      "\n",
      "\n",
      "--- 5. Final Analysis and Model Selection ---\n",
      "Final Comparison of All Models:\n",
      "                        Accuracy  Precision    Recall  F1-Score\n",
      "Logistic Regression     0.988304   0.990654  0.990654  0.990654\n",
      "Support Vector Machine  0.976608   0.981308  0.981308  0.981308\n",
      "SVM (Tuned)             0.970760   0.963636  0.990654  0.976959\n",
      "K-Nearest Neighbors     0.959064   0.938596  1.000000  0.968326\n",
      "Random Forest (Tuned)   0.947368   0.945455  0.971963  0.958525\n",
      "Random Forest           0.935673   0.944444  0.953271  0.948837\n",
      "\n",
      "--- Detailed Report for the Best Model ---\n",
      "The best performing model is: Logistic Regression\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98        64\n",
      "      benign       0.99      0.99      0.99       107\n",
      "\n",
      "    accuracy                           0.99       171\n",
      "   macro avg       0.99      0.99      0.99       171\n",
      "weighted avg       0.99      0.99      0.99       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. SETUP AND IMPORTS\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Import the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# For RandomizedSearchCV distributions\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# 2. LOAD AND PREPARE THE DATA\n",
    "# ==============================================================================\n",
    "print(\"--- 1. Loading and Preparing Data ---\")\n",
    "# Load the dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Create a DataFrame for easier exploration (optional)\n",
    "df = pd.DataFrame(X, columns=cancer.feature_names)\n",
    "# print(df.head())\n",
    "# print(f\"\\nTarget classes: {cancer.target_names}\") # 0: malignant, 1: benign\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# We use stratify=y to maintain the same proportion of classes in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "# Scaling is important for models like Logistic Regression and SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Data prepared: {X_train_scaled.shape[0]} training samples, {X_test_scaled.shape[0]} testing samples.\\n\")\n",
    "\n",
    "\n",
    "# 3. TRAIN AND EVALUATE BASELINE MODELS\n",
    "# ==============================================================================\n",
    "print(\"--- 2. Training and Evaluating Baseline Models ---\")\n",
    "# Define the models to train\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Loop through the models, train them, and evaluate\n",
    "for name, model in models.items():\n",
    "    # Use scaled data for all models for consistency\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }\n",
    "\n",
    "# Convert results to a DataFrame for nice printing\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Baseline Model Performance:\")\n",
    "print(results_df)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 4. HYPERPARAMETER TUNING WITH GridSearchCV (for SVM)\n",
    "# ==============================================================================\n",
    "print(\"--- 3. Hyperparameter Tuning with GridSearchCV (for SVM) ---\")\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "# We'll tune 'C' (regularization), 'gamma' (kernel coefficient), and 'kernel' type\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "# cv=5 means 5-fold cross-validation\n",
    "# n_jobs=-1 uses all available CPU cores\n",
    "grid_search_svm = GridSearchCV(estimator=SVC(random_state=42), \n",
    "                               param_grid=param_grid_svm, \n",
    "                               cv=5, \n",
    "                               n_jobs=-1, \n",
    "                               verbose=1, \n",
    "                               scoring='f1') # We optimize for F1-score\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "print(f\"\\nBest Parameters for SVM: {grid_search_svm.best_params_}\")\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "# Evaluate the tuned SVM model\n",
    "y_pred_svm_tuned = best_svm.predict(X_test_scaled)\n",
    "results['SVM (Tuned)'] = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_svm_tuned),\n",
    "    \"Precision\": precision_score(y_test, y_pred_svm_tuned),\n",
    "    \"Recall\": recall_score(y_test, y_pred_svm_tuned),\n",
    "    \"F1-Score\": f1_score(y_test, y_pred_svm_tuned)\n",
    "}\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 5. HYPERPARAMETER TUNING WITH RandomizedSearchCV (for Random Forest)\n",
    "# ==============================================================================\n",
    "print(\"--- 4. Hyperparameter Tuning with RandomizedSearchCV (for Random Forest) ---\")\n",
    "# RandomizedSearch is great for large search spaces\n",
    "\n",
    "# Define the parameter distribution for Random Forest\n",
    "param_dist_rf = {\n",
    "    'n_estimators': randint(50, 500), # Number of trees\n",
    "    'max_depth': randint(5, 30),      # Max depth of the tree\n",
    "    'min_samples_leaf': randint(1, 10), # Min samples at a leaf node\n",
    "    'min_samples_split': randint(2, 20), # Min samples to split a node\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "# n_iter=50 means it will try 50 different random combinations of parameters\n",
    "random_search_rf = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                                      param_distributions=param_dist_rf,\n",
    "                                      n_iter=50, # Number of parameter settings that are sampled\n",
    "                                      cv=5,\n",
    "                                      n_jobs=-1,\n",
    "                                      random_state=42,\n",
    "                                      verbose=1,\n",
    "                                      scoring='f1')\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "print(f\"\\nBest Parameters for Random Forest: {random_search_rf.best_params_}\")\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "\n",
    "# Evaluate the tuned Random Forest model\n",
    "y_pred_rf_tuned = best_rf.predict(X_test_scaled)\n",
    "results['Random Forest (Tuned)'] = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_rf_tuned),\n",
    "    \"Precision\": precision_score(y_test, y_pred_rf_tuned),\n",
    "    \"Recall\": recall_score(y_test, y_pred_rf_tuned),\n",
    "    \"F1-Score\": f1_score(y_test, y_pred_rf_tuned)\n",
    "}\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 6. FINAL ANALYSIS AND MODEL SELECTION\n",
    "# ==============================================================================\n",
    "print(\"--- 5. Final Analysis and Model Selection ---\")\n",
    "\n",
    "# Create a final DataFrame with all results\n",
    "final_results_df = pd.DataFrame(results).T\n",
    "final_results_df = final_results_df.sort_values(by='F1-Score', ascending=False)\n",
    "\n",
    "print(\"Final Comparison of All Models:\")\n",
    "print(final_results_df)\n",
    "\n",
    "print(\"\\n--- Detailed Report for the Best Model ---\")\n",
    "best_model_name = final_results_df.index[0]\n",
    "if \"SVM\" in best_model_name:\n",
    "    best_model_preds = y_pred_svm_tuned\n",
    "elif \"Random Forest\" in best_model_name:\n",
    "    best_model_preds = y_pred_rf_tuned\n",
    "else:\n",
    "    # Fallback for other models if they happen to be best\n",
    "    best_model_obj = models[best_model_name]\n",
    "    best_model_obj.fit(X_train_scaled, y_train)\n",
    "    best_model_preds = best_model_obj.predict(X_test_scaled)\n",
    "\n",
    "print(f\"The best performing model is: {best_model_name}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, best_model_preds, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595cda24-60d9-4d02-89ba-93e9c5a3b57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading and Preparing Data from CSV ---\n",
      "Data prepared: 398 training samples, 171 testing samples.\n",
      "\n",
      "--- 2. Training and Evaluating Baseline Models ---\n",
      "Baseline Model Performance:\n",
      "                        Accuracy  Precision    Recall  F1-Score\n",
      "Logistic Regression     0.970760   0.983607  0.937500  0.960000\n",
      "K-Nearest Neighbors     0.964912   1.000000  0.906250  0.950820\n",
      "Support Vector Machine  0.959064   1.000000  0.890625  0.942149\n",
      "Random Forest           0.964912   1.000000  0.906250  0.950820\n",
      "\n",
      "\n",
      "--- 3. Hyperparameter Tuning with GridSearchCV (for SVM) ---\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "\n",
      "Best Parameters for SVM: {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "--- 4. Hyperparameter Tuning with RandomizedSearchCV (for Random Forest) ---\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "Best Parameters for Random Forest: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 162}\n",
      "\n",
      "\n",
      "--- 5. Final Analysis and Model Selection ---\n",
      "Final Comparison of All Models:\n",
      "                        Accuracy  Precision    Recall  F1-Score\n",
      "Logistic Regression     0.970760   0.983607  0.937500  0.960000\n",
      "Random Forest (Tuned)   0.970760   1.000000  0.921875  0.959350\n",
      "K-Nearest Neighbors     0.964912   1.000000  0.906250  0.950820\n",
      "Random Forest           0.964912   1.000000  0.906250  0.950820\n",
      "Support Vector Machine  0.959064   1.000000  0.890625  0.942149\n",
      "SVM (Tuned)             0.953216   1.000000  0.875000  0.933333\n",
      "\n",
      "--- Detailed Report for the Best Model ---\n",
      "The best performing model is: Logistic Regression\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.96      0.99      0.98       107\n",
      "   Malignant       0.98      0.94      0.96        64\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.96      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. SETUP AND IMPORTS\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Import the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# For RandomizedSearchCV distributions\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# 2. LOAD AND PREPARE THE DATA (MODIFIED FOR CSV)\n",
    "# ==============================================================================\n",
    "print(\"--- 1. Loading and Preparing Data from CSV ---\")\n",
    "# Load the dataset from your CSV file\n",
    "# Make sure 'data.csv' is the correct path to your file\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# --- Data Cleaning and Preprocessing ---\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "df.drop('Unnamed: 32', axis=1, inplace=True)\n",
    "\n",
    "# Encode the 'diagnosis' column (the target)\n",
    "# We will map 'M' (Malignant) to 1 and 'B' (Benign) to 0\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "target_names = ['Benign', 'Malignant'] # For final report\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop('diagnosis', axis=1)\n",
    "y = df['diagnosis']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# We use stratify=y to maintain the same proportion of classes in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "# Scaling is important for models like Logistic Regression and SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Data prepared: {X_train_scaled.shape[0]} training samples, {X_test_scaled.shape[0]} testing samples.\\n\")\n",
    "\n",
    "\n",
    "# 3. TRAIN AND EVALUATE BASELINE MODELS\n",
    "# ==============================================================================\n",
    "print(\"--- 2. Training and Evaluating Baseline Models ---\")\n",
    "# Define the models to train\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC(random_state=42, probability=True), # probability=True for some metrics\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Loop through the models, train them, and evaluate\n",
    "for name, model in models.items():\n",
    "    # Use scaled data for all models for consistency\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }\n",
    "\n",
    "# Convert results to a DataFrame for nice printing\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Baseline Model Performance:\")\n",
    "print(results_df)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 4. HYPERPARAMETER TUNING WITH GridSearchCV (for SVM)\n",
    "# ==============================================================================\n",
    "print(\"--- 3. Hyperparameter Tuning with GridSearchCV (for SVM) ---\")\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "grid_search_svm = GridSearchCV(estimator=SVC(random_state=42), \n",
    "                               param_grid=param_grid_svm, \n",
    "                               cv=5, \n",
    "                               n_jobs=-1, \n",
    "                               verbose=1, \n",
    "                               scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "print(f\"\\nBest Parameters for SVM: {grid_search_svm.best_params_}\")\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "# Evaluate the tuned SVM model\n",
    "y_pred_svm_tuned = best_svm.predict(X_test_scaled)\n",
    "results['SVM (Tuned)'] = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_svm_tuned),\n",
    "    \"Precision\": precision_score(y_test, y_pred_svm_tuned),\n",
    "    \"Recall\": recall_score(y_test, y_pred_svm_tuned),\n",
    "    \"F1-Score\": f1_score(y_test, y_pred_svm_tuned)\n",
    "}\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 5. HYPERPARAMETER TUNING WITH RandomizedSearchCV (for Random Forest)\n",
    "# ==============================================================================\n",
    "print(\"--- 4. Hyperparameter Tuning with RandomizedSearchCV (for Random Forest) ---\")\n",
    "\n",
    "# Define the parameter distribution for Random Forest\n",
    "param_dist_rf = {\n",
    "    'n_estimators': randint(50, 500),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "random_search_rf = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                                      param_distributions=param_dist_rf,\n",
    "                                      n_iter=50, \n",
    "                                      cv=5,\n",
    "                                      n_jobs=-1,\n",
    "                                      random_state=42,\n",
    "                                      verbose=1,\n",
    "                                      scoring='f1')\n",
    "\n",
    "random_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "print(f\"\\nBest Parameters for Random Forest: {random_search_rf.best_params_}\")\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "\n",
    "# Evaluate the tuned Random Forest model\n",
    "y_pred_rf_tuned = best_rf.predict(X_test_scaled)\n",
    "results['Random Forest (Tuned)'] = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_rf_tuned),\n",
    "    \"Precision\": precision_score(y_test, y_pred_rf_tuned),\n",
    "    \"Recall\": recall_score(y_test, y_pred_rf_tuned),\n",
    "    \"F1-Score\": f1_score(y_test, y_pred_rf_tuned)\n",
    "}\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 6. FINAL ANALYSIS AND MODEL SELECTION\n",
    "# ==============================================================================\n",
    "print(\"--- 5. Final Analysis and Model Selection ---\")\n",
    "\n",
    "# Create a final DataFrame with all results\n",
    "final_results_df = pd.DataFrame(results).T\n",
    "final_results_df = final_results_df.sort_values(by='F1-Score', ascending=False)\n",
    "\n",
    "print(\"Final Comparison of All Models:\")\n",
    "print(final_results_df)\n",
    "\n",
    "print(\"\\n--- Detailed Report for the Best Model ---\")\n",
    "best_model_name = final_results_df.index[0]\n",
    "if \"SVM\" in best_model_name:\n",
    "    best_model_preds = y_pred_svm_tuned\n",
    "elif \"Random Forest\" in best_model_name:\n",
    "    best_model_preds = y_pred_rf_tuned\n",
    "else:\n",
    "    best_model_obj = models[best_model_name]\n",
    "    best_model_obj.fit(X_train_scaled, y_train)\n",
    "    best_model_preds = best_model_obj.predict(X_test_scaled)\n",
    "\n",
    "print(f\"The best performing model is: {best_model_name}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "# Use the target_names we defined during data prep\n",
    "print(classification_report(y_test, best_model_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184aba21-f76c-4370-8563-16dc5f937733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
